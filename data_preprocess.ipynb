{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNR1G/l6jBTkCweJuD1N9FF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thisiscd/RecommendSystem/blob/main/data_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDvoiFzRs8Vz",
        "outputId": "1d4ecd68-7fb1-4d54-88fc-069650f066cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 文件位置\n",
        "path = '../data/'\n",
        "# 当前的路径\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/RecommendSystem/NCF\")"
      ],
      "metadata": {
        "id": "kOZJET8QtJWh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Jun  6 01:37:27 2023\n",
        "\n",
        "@author: chendu\n",
        "\"\"\"\n",
        "\n",
        "# 数据读取与处理\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 深度学习\n",
        "from tensorflow.keras import models, layers, utils  #(2.6.0)\n",
        "\n",
        "path = '../data/'\n",
        "\n",
        "dtf_users = pd.read_csv(path + 'dtf_users.csv')\n",
        "dtf_items = pd.read_csv(path + 'itemAttribute.csv')\n",
        "\n",
        "embeddings_size = 50\n",
        "usr, prd = dtf_users['userid'].unique().size, dtf_items.shape[0]\n",
        "\n",
        "print(usr)\n",
        "print(prd)\n",
        "\n",
        "# 用户 Users 维度(1,embedding_size)\n",
        "xusers_in = layers.Input(name=\"xusers_in\", shape=(1,))\n",
        "xusers_emb = layers.Embedding(name=\"xusers_emb\", input_dim=usr, output_dim=embeddings_size)(xusers_in)\n",
        "xusers = layers.Reshape(name='xusers', target_shape=(embeddings_size,))(xusers_emb)\n",
        "# 产品 Products 维度(1,embedding_size)\n",
        "xproducts_in = layers.Input(name=\"xproducts_in\", shape=(1,))\n",
        "xproducts_emb = layers.Embedding(name=\"xproducts_emb\", input_dim=prd, output_dim=embeddings_size)(xproducts_in)\n",
        "xproducts = layers.Reshape(name='xproducts', target_shape=(embeddings_size,))(xproducts_emb)\n",
        "# 矩阵乘法，即我们我们上面提到的因子矩阵相乘 维度(1)\n",
        "xx = layers.Dot(name='xx', normalize=True, axes=1)([xusers, xproducts])\n",
        "# 预测得分 维度(1)\n",
        "y_out = layers.Dense(name=\"y_out\", units=1, activation='linear')(xx)\n",
        "# 编译\n",
        "model = models.Model(inputs=[xusers_in,xproducts_in], outputs=y_out, name=\"CollaborativeFiltering\")\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mean_absolute_percentage_error'])\n",
        "\n",
        "utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "train = dtf_users\n",
        "# 训练\n",
        "training = model.fit(x=[train[\"userid\"], train[\"itemid\"]], y=train[\"rating\"], epochs=100, batch_size=128, shuffle=True, verbose=1, validation_split=0.3)\n",
        "model = training.model\n",
        "# 测试\n",
        "test = train\n",
        "test[\"rating_hat\"] = model.predict([test[\"userid\"], test[\"itemid\"]])\n",
        "\n",
        "print(test['rating_hat'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeKg9EhkruYP",
        "outputId": "d5ef4837-b146-4811-f3a4-250eb5f7db3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19835\n",
            "507172\n",
            "Epoch 1/100\n",
            "20787/27352 [=====================>........] - ETA: 1:05 - loss: 41.6516 - mean_absolute_percentage_error: 2855718400.0000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 工具库导入"
      ],
      "metadata": {
        "id": "qkzQN_kjsbEr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN2VruJ5rnoe"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "工具库导入\n",
        "\"\"\"\n",
        "\n",
        "# 评估与预处理\n",
        "from sklearn import metrics, preprocessing\n",
        "\n",
        "# 数据读取与处理\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 绘图\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_data(path):\n",
        "    users = []\n",
        "    items = []\n",
        "    ratings = []\n",
        "    for line in open(path, 'r'):\n",
        "        if not line.find('|') == -1:\n",
        "            (user_id, item_num) = line.strip('\\n').split('|')\n",
        "            users.extend([int(user_id) for _ in range(int(item_num))])\n",
        "        else:\n",
        "            (item_id, rating) = line.strip('\\n').split('  ')\n",
        "            items.append(int(item_id))\n",
        "            ratings.append(int(rating))\n",
        "        \n",
        "    users_data = np.column_stack([users, items, ratings])\n",
        "    dtf_users = pd.DataFrame(users_data, columns=['userid', 'itemid', 'rating'], dtype=int)\n",
        "    return dtf_users\n",
        "\n",
        "def get_item_attribute(path):\n",
        "    return pd.read_table(path, sep='|', names=['itemid', 'attribute1', 'attribute2'])\n",
        "\n"
      ],
      "metadata": {
        "id": "JjFGD5Qur9e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 读取数据"
      ],
      "metadata": {
        "id": "nZ2lw5a2sgNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 将 txt 转换为 csv 格式\n",
        "dtf_users = get_user_data(path + 'train.txt')\n",
        "dtf_users.to_csv(path + 'dtf_users.csv', index=False)\n",
        "dtf_items = get_item_attribute(path + 'itemAttribute.txt')\n",
        "dtf_items.to_csv(path + 'itemAttribute.csv', index = False)\n",
        "\n"
      ],
      "metadata": {
        "id": "sgb6I2cDsDzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 读取数据\n",
        "dtf_users = pd.read_csv(path + 'dtf_users.csv')\n",
        "dtf_items = pd.read_csv(path + 'itemAttribute.csv')\n",
        "dtf_items = dtf_items.set_index('itemid')\n",
        "# print(dtf_items.head(10))\n"
      ],
      "metadata": {
        "id": "6hjSEmpHsJwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 数据分析 && 特征工程"
      ],
      "metadata": {
        "id": "Gtt9RaywskQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    数据分析 && 特征工程\n",
        "\"\"\"\n",
        "\n",
        "# 属性缺失字段处理 TODO:\n",
        "# print(dtf_items)        \n",
        "# dtf_items = dtf_items[~dtf_items['attribute1'].isna()]\n",
        "# dtf_items.dropna(thresh= 2)\n",
        "# dtf_items['attribute1'].astype('Int64')\n",
        "# dtf_items.astype('Int64')\n",
        "# print(dtf_items)     \n",
        "\n"
      ],
      "metadata": {
        "id": "7L_t4rSTsL4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 构建 Item-Attribute 矩阵"
      ],
      "metadata": {
        "id": "cHL89TxQspm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 构建 Item-Attribute 矩阵\n",
        "\"\"\"\n",
        "attribute = [ a for a in dtf_items['attribute1'].unique()]\n",
        "attribute.extend([a for a in dtf_items['attribute2'].unique()])\n",
        "columns = list(set(attribute))\n",
        "# 将属性切分出来作为标签\n",
        "for col in columns:\n",
        "    dtf_items[col] = dtf_items.apply(lambda x: 1 if col in x[\"attribute1\"] or col in x[\"attribute2\"] else 0, axis=1)\n",
        "dtf_items.to_csv(path + 'dtf_items.csv')\n",
        "\"\"\"\n",
        "# 构建热力图并可视化\n",
        "\"\"\"\n",
        "#print(dtf_items.head(4))\n",
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "sns.heatmap(dtf_items==0, vmin=0, vmax=1, cbar=False, ax=ax).set_title(\"Items x Attributes\")\n",
        "plt.show()\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "YeZ8GFkGssPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# user-item矩阵"
      ],
      "metadata": {
        "id": "TUSLtvdbstjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# user-item矩阵\n",
        "tmp = dtf_users.copy()\n",
        "dtf_users = tmp.set_index(['userid', 'itemid'])['rating'].unstack('itemid')\n",
        "missing_cols = list(set(dtf_items.index) - set(dtf_users.columns))\n",
        "\n",
        "missing_data = pd.DataFrame(np.nan, index=dtf_users.index, columns=missing_cols)\n",
        "dtf_users = pd.concat([dtf_users, missing_data], axis=1)\n",
        "#for col in missing_cols:\n",
        "#    dtf_users[col] = np.nan\n",
        "\n",
        "dtf_users = dtf_users[sorted(dtf_users.columns)]\n",
        "\n",
        "\"\"\"\n",
        "print(dtf_users.head(5))\n",
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "sns.heatmap(dtf_users==0, vmin=0, vmax=1, cbar=False, ax=ax).set_title(\"Users x Items\")\n",
        "plt.show()    \n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "vq8lH_vRsPih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 数据幅度缩放"
      ],
      "metadata": {
        "id": "MMDyREA1sweY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 数据幅度缩放\n",
        "\"\"\"\n",
        "dtf_users = pd.DataFrame(\n",
        "                        preprocessing.MinMaxScaler(feature_range=(0.5,1)).fit_transform(dtf_users.values), \n",
        "                        columns=dtf_users.columns, \n",
        "                        index=dtf_users.index\n",
        "                        )\n",
        "\"\"\"\n",
        "# print(dtf_users.head(5))"
      ],
      "metadata": {
        "id": "CugD3yFosRtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 划分训练集和测试集"
      ],
      "metadata": {
        "id": "gDBMBUAMs0o6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(0.8*dtf_users.shape[1])\n",
        "dtf_train = dtf_users.loc[:, :split-1]\n",
        "dtf_test = dtf_users.loc[:, split:]\n",
        "\n",
        "dtf_train.to_csv(path + 'trainset.csv')\n",
        "dtf_test.to_csv(path + 'testset.csv')"
      ],
      "metadata": {
        "id": "4_zAutXWs3QD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}